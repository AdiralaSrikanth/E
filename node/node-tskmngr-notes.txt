Databases and mongodb

connect to database
user authentication
data storage in db of user
file uploads for user profile pic 
email notifications
CRUD
Database - we are using mongodb to store user data.
J14
mongodb.com --- open source and available for all operating systems

No sql - not only structured query language

mongodb provides npm module that can be used to read and write to database

sql vs nosql
database > table(s) > individual items - row or record > column
database > collection(s) > document(s) - looks like json  > fields
A collection is a list of entries those entries are reffered as documents and documents have many fields.

installing mongodb
start up mongodb server and connect with node js

download server - community - based on OS
for linux - version - 4.0.X OS - ubuntu, pkg T0Z - download

Navigate to download folder - extract files > bin dir - contains executables to perform various tasks
main one is > mongod executable- used to startup the mongodb server

move this folder to user directory (permanent location)

Now, create a place for our data to get store. by default mongodb expects you to create a data directory at the root of your harddrive
in that place it expects db directory. will have permissions issue so create a folder in user directory
create folder "mongodb-data" in user directory which has mongodb {executables}

Terminal:
cd ~  --Navigates to user directory
pwd - print working directory
return path /users/aaaa
to start mongodb server - 
<path to mongod executable> --dbpath=<path to data folder>
/users/aaa/mongodb/bin/mongod --dbpath=/users/aaa/mongodb-data

initialize database and gets the db up and running. 
now go to mongodb-data and observe data is generated. 

installing database GUI viewer: robo3t (earlier robomongo) - mongodb admin tool - open source
download and install mongo 3t

opens mongodb connections panel > create connection > name-local mongodb > address - localhost and port - 27017

open shell > db.version() - method on db object - it is js

connecting to mongodb database from nodejs and inserting document :
we use monogdb native driver - npm module > allows us to interact with our database using nodejs.

docs.mongodb.com > docs > drivers > drivers are libraries that allow you to interact 
with the mongodb database from wide range of programming language

c,java,node,php,python --> click on nodejs > see/find the native driver for the platform

release and API section - click on API --> returns to documentation

google - mongodb npm module -- official native driver released by mongodb.
1. leave the current terminal, database server needs to be up and running in order us to connect to it. do not shut it down.
2. Open up new terminal

create a proj and open in vsc
npm init -y --> pkg.json
npm install mongodb@3.1.0
Now we can use driver and connect to our database and insert some data

file > mongodb.js
learning CRUD operations

const mongodb = require('mongodb') //returns object
to initialize connection
const MongoClient = mongodb.MongoClient
MongoClient give us access to the function neccessary to connect to our db so we can perform CRUD operations

we need to define connection url and db we are trying to connect to.

const connectionUrl = 'mongodb://127.0.0.1:27017' ---->connect to localhost url which is up and running. 
mongodb:// --> following their protocol, 
instead of localhost we are using ip address sometimes localhost has strange issues 

const databaseName = 'task-manager'
connect to our database/server
 
MongoClient.connect() -- connect method, takes 3 arguments 1. connectionurl 2. options object {useNewUrlParser : true -->parses url}
3. callback function- takes two arguments error and client, if we fail to connect to db, gives error and if we succeed, gets client

Connecting to a database is asynchronous operation. takes time for connection. callback will run when the connection is complete

MongoClient.connect(connectionurl, {useNewUrlParser : true -->parses url}, (error, client)=>{
        if(error) {
            return console.log('Unable to connect to database')
        }
        console.log('connected successfully')
    })
in other terminal where mongodb server running, we can see the connections with ip and port

in second terminal where we are running node app, it is still hanging and hasnt brought to normal command.

once the connection is opened, node process is up and running as long as connection active. can shut down.

insert doc:

MongoClient.connect(connectionurl, {useNewUrlParser : true -->parses url}, (error, client)=>{
        if(error) {
            return console.log('Unable to connect to database')
        }
       const db =  client.db('databaseName') //we store database name in databaseName variable, you dont have to mention, mongodb will create db if you dont mention
                        //db method takes database name and return database reference. can be used to manipulate data

//collection is a function and expects name of the collection
        db.collection('users').insertOne({
            name: 'srk',
            age: 26
        })
    //call a method on collection reference - insertOne() expects object as argument
    //inserting a document into users collection.
     })
save the file and run node mongodb.js
open robo3t --> right click the connection and refresh the shell > 
newly created database will be visible > collections
> users {we created} >right click collection > view documents

_id     //stores unique identifier for that particular doc. mongodb generates it //similiar to sql which generates increment id.
name
age
when you insert a document, it will have unique id automatically generated for us.

insertOne is asynchronous. we did not use callback above. it is not neccessary now but with prod app it is neccessary
if we want to handle errors or want to know that our operation performed as expected

 db.collection('users').insertOne({
            name: 'srk',
            age: 26
        }, (error, result)=> {   //second argument to insertOne, a callback which gets called when the operation is complete
                                //error or result - if things went well //result has operation result -which has data as well as the unique id  
            if(error) {
                return console.log('Unable to insert user')
            }
            console.log(result.ops) //on result we use one property called 'ops' - contains all of the documents (array of documents) that were inserted
        })
     })
save the file and run node mongodb.js command in terminal
returns inserted doc.

how will I know about 'ops' on result?? go to nodejs driver doc  > MongoClient > on MongoClient we have a method - connect > doc on that connect method

check the same for insertOne. collection>methods>insertOne>documentation.
insertOne - inserts one doc.
insertMany - inserts many doc

db.collection('users').insertMany([{
            name: 'srk',
            age: 26
        }, {
            name:'bob',
            age: 26
        }
        ], (error, result)=>{
            if(error){return console.log('unable to insert docs')}
            console.log(result.ops)
        })
     })
save the file and run node mongodb.js command in terminal
open robo3t and verify the inserted docs. 
J15
The objectID:
automatically created by mongodb and stores unique identifier for each document you insert into database.

GU ids - globally unique identifier. ability to scale up in a distributed system. 
multiple database servers running instead of one, allowing us to handle heavy traffic, multiple queries coming in
there is no chance of ids collision across all database servers. with increment id approach of sql, there may be a chance
of ids collision. a user will have a increment id (id=2)in one database server
and the other user will have same increment id (id=2) in other database server - id conflict

we can generate ids for our document before inserting them to our database.
instead of mongodb server generating ids, we can use mongodb library to generate our own objectID.

const {MongoClient, ObjectID} = require('mongodb') //returns obj and we need the prop of that object hence destructured.

const id = new ObjectID() //constructor function thats y new keyword and takes no arguments. generates id 
console.log(id) //5c1110c5c6cdac04f740575b - count 24
lets talk about id value. 5c1110c5c6cdac04f740575b
google - mongodb ObjectID > reference doc not api doc.

The 12byte ObjectID value consists of, 
1. a <4byte timestamp> representing the seconds since the unix epoach (point of units - midnight jan 1970)
2. <5 byte random no.>
3. <3byte counter. starting with a random value.>
combination of all these generates robust id. no need of server telling increment the id

open ObjectID node js doc. see the available methods
we use getTimeStamp() method - which returns generation date. returns the generation date(accurate upto the second) that this id was generated.

const id = new ObjectID()
console.log(id) //id that we generated.
console.log(id.getTimeStamp()) //prints the timestamp

db.collection('users').insertMany([{
            _id: id,     //for _id value we are using the id we generated. check the id of this doc and the id we generated -will be same
            name: 'srk',
            age: 26
        }, {
            name:'bob',
            age: 26
        }
        ], (error, result)=>{
            if(error){return console.log('unable to insert docs')}
            console.log(result.ops)
        })
     })
Above example is of - we can provide our own ids to the documents if we want to. we dont use it as it is extra work, mongodb will automatically generates it

How object ids are stored: 
ObjectID("5c1110c5c6cdac04f740575b") -- function call and a string is provided as a argument.
The above statement is for visualization purpose to see what's the id value. ids are binary data.
by storing binary data instead of string cuts half of the memory (size)

const id = new ObjectID()
console.log(id.id.length) //id has a prop of id - contains raw binary data
<buffer 5c 11 ... >
and can see the length - 12 (same as 12bytes we saw in documentation)
console.log(id.toHexString().length) //string representation, gives the length of 24 (double of original value)
ObjectID("5c1110c5c6cdac04f740575b")
so for visualization they put string and is a argument to a ObjectID function call, it then converts to binary data n store 
abstracts all from user.

Querying documents:
Read documents from database
1. find({}) -- fetch multiple documents out of the database. doesnt takes callback, returns cursor.
2. findOne({},cb)

db.collection('users').findOne({name: 'bob}, (error, user)=> {
    if(error) {return console.log('Unable to fetch user')}
    console.log(user) //if user found, returns user document object
})

//findOne accepts two arguments 1.obj 2. function
1.obj - specifiy search criteria ex: name
2. callback gets called when the operation is complete. either we get error or the document

db.collection('users').findOne({name: 'bob, age:1 }, (error, user)=> {
    if(error) {return console.log('Unable to fetch user')}
    console.log(user) 
})
There is no user with age 1, it did not throw error, output is null.
searching for a document and not finding it is not a error.

**if there are two users with name bob, findOne return the first match document. 
use ObjectID to uniquely identify that doc

db.collection('users').findOne({_id: new ObjectID("objectid..") }, (error, user)=> {})
will learn to avoid new keyword, it is standard way of doing when using mongodb native driver.

2. find({}) - doesnt makes sense if we use objectID as its gonna return one doc. find is used to return multiple documents

db.collection('users').find({age: 27}) it doesot take cb as second argument. return value is a cursor
cursor is a pointer to that data in the database. 
mongodb assume, everytime you use find, you always want to get back an array of all those documents.
other things you might want to do - get the first five documents (limit) or get the count (count) of matching documents. just the count not the documents

nodejs mongodb driver api documentation > cursor

find return cursor > cursor has methods> limit or count or toArray methods etc
1.
db.collection('users').find({age: 27}).toArray((error, users)=>{ //toArray takes cb, either error or documents here users
    console.log(users) //lists users(documents) with age as 27 as a array
})
2. db.collection('users').find({age: 27}).count((error, count)=>{ 
    console.log(count) //returns count - simple integer count as 3 not the entire matching documents sending through wire 
})
Cursor advantage: sometimes I want to get the data (Ex:1) and sometimes I just want to get the matching documents count (ex:2)

***** Call backs explanation:
We need them because a lot of operations in JavaScript are asynchronous, or put a bit more simply they don't actually stop
the program from continuing until they are done like you are probably used to. But instead just run in the background 
while the rest of the code continues executing.

If you wanted to fetch some data from a server for instance (which could takes an unknown amount of time) 
it would be incredibly inefficient for your program to just freeze completely while it waited for that data to be fetched. 
So instead of doing that it's common to just run the fetching task in the background.

This means that if you have two functions in a row with function A being asynchronous then function B will be executed 
while function A is still running. In that case if function B depends on data that function A is fetching you will 
run into problems.

This problem is solved with callbacks. With a callback you can guarantee that function B is only called after 
function A is finished with its thing because function A is actually the one responsible for calling function B.

Asynchronous functions also aren't the only use of callbacks, but they are the most common and useful use of them 
that I can think of at the top of my head.
---------------------------------------------------------------------------------------------------

Promises:
make it easy to manage asyn code 
solve callbck problems
build on cb pattern. enhancement for cb's.

callback func:
---------------
const doWorkCallBack = (callback) =>{ //callback parameter
         setTimeout(()=>{                                           //simulating asyn process
              callback('This is my error', undefined)               //asyn task is complete (post 2secs) we need to signal the caller that we either got error or result
         },2000)                                                    //call back runs after 2secs                           
}

doWorkCallBack((error, result)=>{   //call back runs when I have either error or result.
       if(error) {return console.log(error)}                             //write logic here
    console.log(result)
})
whole point of using callback pattern is a way to allow the caller of doworkcallback to get the results
callback(undefined, result) - for result
callback('This is my error', undefined)-for error :::: o/p: This is my error.

Promises func:
--------------
to create a promise we use new keyword with Promise constructor function. takes 1 argument - callback func. -->takes two arguments resolve and reject functions as arguments
As nodejs developers, we are not going to create promises, typically they are created by the libraries we use
const doWorkPromise = new Promise((resolve, reject)=>{
        setTimeout(()=>{
            resolve([1,2,3])  //after 2secs we are ready to signify that we completed the asynchronous process
                                        //instead of using cb's we can use resolve - if we get the results that we expect or reject methods -error
                                        //callback('This is my error', undefined) - order is imp in cb whereas in promises func names signifies the success and error
            //reject('this is error')
        },2000)
})

promise is a obj and has methods like then and catch. doWorkPromise return a promise

doWorkPromise.then((result)=>{    //when everything goes well, it comes under .then block and has result as argument.
    console.log(result)     //[1,2,3]
}).catch((error)=>{            //query the db - network connection drops -cannot access db server then you can call reject, it comes to .catch
    console.log(error)
})

advantages:
clear semantics, easier to understand the intension of the code. resolve-reject
cb's - we have to find all callbacks nd we need to figure out which are the arguments that are provided - error prone.
we have one cb func nd we need to idenify error or result using if, whereas in promises you haveaccess to 2 func. resolve nd reject

in promises, we cannot call both resolve nd reject or two resolve/reject. once we call resolve/reject, then promise isdone.
we cannot change the state. failure to success
in cb's - we can use multiple callbacks pass/fail - no preventive measures can easily mess up.

                        fulfilled (resolved)
                     /
promise ------>pending   
        {asyn task}   \
                     rejected (reject)

Updating documents: updateOne, updateMany
update is depreciated.

if you do not use callback, updateOne returns promise
const updateprof = db.collection('users').updateOne({      //filter, update and callback or can use promise
    _id: new ObjectID("object id")      //targeting doc with id.
    },{
    $set: {                 //$set command is used to update the field , not part of api doc,{search google - update operators mongodb - reference doc}
        name: 'mich'        //updating name field. age field remains same.
          }
    })
updateprof.then((result)=>{  //we can remove updateprof variable and chain .then together - this runs for success case.
        console.log(result) //result have lot of stuff, useful - modified count - updateone so 1 or 0.
    }).catch((error)=>{
        console.log(error)
    })

$inc -- increment by
Sinc: {
    age:1   //increment age by 1.
    } 
//check robo3t for updates of documents.

Delete documents: deleteOne and deleteMany
deleteOne(filter,options,callback) return (promise)

const updateprof = db.collection('users').deleteMany({
        age: 27
}).then((result)).catch()

result -- deletedCount:2

Restapi and mongoose
express based rest api.
allow user to perform operations such as
signup
add task
fetch all tasks

mongoose -popular library when working with node & mongodb - easy system for modelling our data - for modelling things like a user or task
fields and datatypes and data validation.

setting up mongoose:
npm module mongoose - mongoose directly related to mongodb
allows us to do some of the things that we do not know how to do so far.
we know how to do CRUD operations, but what about the things
1. how do I set up validation for my documents defining which fields are required and which are optional
2. what types of data to expect for the fields ex: completed:true, it should be boolean not a string or number.
3. If user1 creates a task and I dont want user 32 to view that task - add authentication 
4. also allows us to do basic crud operations on mongodb database.

mongoosejs.com ->
ex given in that website. mongoose performing tasks
1. connect to db
2. create cat model
3. create new instance of cat model new Cat()
4. save to db.

2. model:
allows us to model something in real world that we gonna able to store it in database
ex: user /cat/furnitures /task
create models for collections that we want and use model to describe the data.{fields}

ODM - object doc mapper - map ur obj in ur code over to doc inside mogndb db.

npm i mongoose@3.1.16

folder strucure: appname>src folder- app source code will live>db folder > mongoose.js file
const mongoose = require('mongoose')
mongoose.connect() // we use it to connect to database. 
takes two arguments 1.connectionurl ---> <mongodb://ip&port<databaseName>>, 2. options object

mongoose uses mongodb behind the scenes
connect to db:
mongoose.connect('mongodb://127.0.0.1:27017/task-manager-api', {
    useNewUrlParser: true,
    useCreateIndex: true      //when mongoose work with mongodb, indexe's are created allowing qucikly access the data.
})

defining the model:
const User = mongoose.model('User', {       //accepts two arguments 1. model string name 2. definiton where we define the fields that we want
                        //set up all the fields as prop's on this obj.
    name: {             //field and whose value is a object
        type: String   //type of the field to accept string/number.
    },
    age: {
        type: Number
    }   
})
               
creating instance of the model to add documents to the database

const me = new User({   //use new keyword and constructor func for that model.
    name: 'srk',        //data, should match with the type we defined.
    age:26
})
not saving to database yet, we need to use methods available on the instance (here me)

in order to save model instance
me.save().then((me)=>{            //save method does not take arguments, it saves data in db. it returns promise
        c.l(me)                    //wait for saving process to finish, then it either resolve or reject.
                                //when things go well, we get access to our instance model
}).catch((error)=>{
    c.l(error)
})    
.then or .catch -> register a handler when the promise is fulfilled/rejected

***Data validation and sanitization:

Data validation: data confronts to some rules 
ex: user age >=18
Sanitization: Alter the data before saving it
ex: removing empty spaces around user name - trim.

mongoosejs.com docs
validation
1. setup some of our fields required {required: true}

inside model:
name: {
    type: String,
    required: true //you have to provide name field while creating a user. field without required are optional we can add to db without them
}
mongoose documentation
Builtin validator : there are less validators
1. All schematypes have the built in validator. 
2. Numbers have min and max validator. String have enum,match, minlength and maxlength.
To validate valid email or social cvv number or validate user age >10 etc, mongoose does not provide many validators

mongoose allows us to setup custom validation , allowing to validate anything
we can customize our own validator, using validate function,

age: {
    type: Number,
    required: true
    validate(value) {    //es6 func. takes one argument on that field. based on type "value" will be there number/string etc.
        if(value<0) { //ppl should not enter negative age if yes throw error
            throw new Error('User age should be positive') //using js Error method to return error
        }
    }
}
we can also use Validator npm library to verify more complex things like valid email, social cvv number etc. instead of
we spending time on writing validation code we can use libraries to save time n effort.

npm validator
npm i validator@10.9.0
load library in our app.
const validator = require('validator)

email: {
    type: String,
    required: true
    validate(value) {    //es6 func. takes one argument on that field. 
        if(!validator.isEmail(value)) { //validator module has isEmail() func takes in string and returns true or false
                                    //if you provide wrong email it returns false and we flip it to true to print error
            throw new Error('Please enter valid email') //using js Error method to return error
        }
    }
}
error obj -if something is wrong. comes under .catch() of save() promise. our error we will under message.

mongoose has other validators under schematypes {string,number,date,boolean,array etc}
list of options available for each schematype:
default  --can set default value - age:0 or name: anonymous
trim
lowercase
email: {
    type: String,
    required: true
    trim: true  //trims extra spaces.
    lowercase: true //coverts to LowerCase
    validate(value) {    
        if(!validator.isEmail(value)) {
            throw new Error('Please enter valid email')
        }
    }
}
**Using all above prop's, will have more control over the data that we are allowing to database

Structuring a Rest api:
Till now we defined models and we know how to create instances using those models and storing data in database

{http endpoints for tasks app:}

Restful api:
api - gives set of tools to build software app.

node provides apis like fs
express provides apis - provides set of tools that allow us to build soft app.

restapi we are creating also provides tools that allows others to build software.

REST - allows clients-webapps to access and manipulate resources using set of predefined operations
resource - user or task. 
predefined operations - create a new task or mark a task as complete
upload prof pic.

These predefined operations allow the client/webapps to go through the process of creating a front end for task manager

Representational - with a rest api we are getting and working with representation of our data. 
data is stored in database but using restapi
I can fetch data and manipulate data - CRUD operation
we are working with represention of our users and tasks

state transfer: a rest api, the server is stateless the state has been transfered from server to client
each request from client such as a req from a webapp app contains everything needed for the server to process that request
includes the operation they are trying to perform {GET}
all of the data the operation needs in order to work
authentication making sure that the user who is performing the operation is authenticated

requests are made via http requests
client/webapp able to perform predefined operation

client >>need task data to show >> make a http request to a specific url on the server >> GET /tasks/a7eee>>server> server finds the data in db
>>server>>send back as part of http response>>>200 status code - JSON response>>client render the data.

POST  req- status code 201 - resource created.

client>srk - authenticating>>request> POST /tasks - JSON request {sending along json with req ex:desc and completed status}>>>
server authenticate the user>>>create that task/todo associated with us>> sends response -- 201 hhtp status code - resource created>> 201-JSON response>>client >render data 

Predfined operations for our resources:
we need to expose our predefined operations ex: CRUD operations
                        create  POST /tasks      // every single rest api defined with two pieces of data 1.http method 2. path
TASK RESOURCE           read    GET /tasks          //path is same
                        read    GET /tasks/:id   //id is placeholder and is dynamic

                        update PATCH /tasks/:id
                        delete DELETE /tasks/:id

/tasks is a pluralized resource.

we gonna send 100s of http request b/w client and server. what we gonna send in request? we send text
Request:
POST /tasks HTTP/1.1     ---> request line --contains http method, the path and http protocol
Accept: application/json        //expecting json data back
Connection: keep alive           //3 request headers, allows you to attach meta data to req
Authorization: Bearer eysfsdfdsfdfsds      //setup authentication.

{description: "order new books"}    //request body. post data and provided as json.

Response:
Http/1.1 201 created        //status line protocol, status code, text represention of status code
Date: sun 28 jul 2019 15.30 
Server - Express                //response headers
content-type: application/json

{"_id": "5cdddd", "des..":"ordd..", "completed": "false"}  //response body.

installing postman - allowing us to verify our rest api working as expected without the UI/client.
getpostman.com. - download the app.
create request.
collection - store related requests

homepage -
httpmethod - GET/POST
url that we are trying to make request to.
GET url/weather?address=hyd {can add address in params sec as key value pair} /weather - endpint 
hit send button.

communicate with the server and gets response. body >pretty/raw
can see status code and time took and size of http response.

Resource creation endpoints:
endpoints involve resource creation

install nodemon as dev dependency -- npn i nodemon@v --save-dev --> to save nodemon as dev dependency
npm i express

scripts: {
    "start": "node src/index.js"
    "dev": "nodemon src/index.js"
}

create index.js file under src folder
const express = require('express')
const app = express() //create express app.
const port = process.env.PORT || 3000 //as we deploy to heroku so using port from env variable
const user = require('./')

app.post('/users', (req,res)=>{ 
    res.send('testing')
})

app.listen(port, ()=>{console.log('listening at port'+ port)})

postman>createcollection>request>users
post localhost:3000/users    send //gets the response

data from client to server -- json data via req body
body tab>raw>json

{
    "name":"srk",
    "email":"test@test.com"
    "password": "res123"
}
hit send , status code 200

in the route how can we access the data sent?
two step process
1. json is sent so we need to configure express app.use(express.json()) -->converts json to object {{parses incoming json}}
2. we can use obj in route and is accesible under req. req.body

now we can create a new user. --> mongoose connects to database and we need access to model in this file

refactor folders --> 
src>models>user.js>>> put all models into individual files under models folder. ex: user model in user.js file etc
check the modules and require them in files

module.exports = User
exporting User model

index.js file
require('./db/mongoose.js')//returns nothing we just need mongoosejs file gets called results in connecting to database server
const user = require('./models/user')

app.post('/users', (req,res)=>{ 
    const user = new User({ req.body})//constructor func. requires us to pass obj with all the attributes. we have all those in req.body
 
    user.save().then(()=>{  //save to db. .then handles success
        res.status(201).send(user)       //in the example, did not put user in then cb func. recheck
    }).catch((error)=>{
        res.status(400).send(error)     //we need to send status code as well, currently for error it is sending status code as 200, change it 400
    })                  

})
senddata to server via http req using predefined operation we are able to perform some manipulation on database

httpstatuses.com

J16
Resource reading endpoints:
list of multiple items 
one item.

app.get('/users', (req,res)=>{
          //fetch users from db using mongoose                   
})

//we use mongoose to fetch all the users from database.
mongoose provides series of methods similar as mongodb native driver.

mongoosejs>doc>queries> list of methods available directly on model
ex: Model.deleteMany()
Model.updateOne(), Model.findOne() etc

app.get('/users', (req,res)=>{
    User.find({}).then((result)=>{    //on user model we use find method which returns promise n find takes object -find({}), define search criteria inside. finds all
        res.status(200).send(result) //if we find users we send users as result and status code of 200
    }).catch((error)=>{res.status(500).send()}) //sending internal server error
})

postman>new req in collection > read users >
GET localhost:3000/users send //returns array of users

/:id dynamic - capture the value and access that in route handler 
to do that express gives us route parameters, parts of url that are used to capture dynamic value

app.get('/users/:id', ()=>{ get request with /users/something,
    //req.params -->contains all of the route parameters that we are provided. here obj with single prop i.e id and its dynamic value
    console.log(req.params)  //new req> read user> GET localhost:3000/users/6737737373 -->as we are not sending anything postman loading screen appear
           //o/p in vsc : {id: "6737737373"} --id we are sending as route parameter and can see the value provided
})

Now we know how to access the value passed as route parameter, now we will find that user in db and return that user if any

app.get('/users/:id', (req,res)=>{ 
    const _id = req.params.id
    User.findById(_id).then((user)=>{ //findOne or findById query method - findById() does not take obj {}, just takes id 
        if(!user) {
            return res.status(404).send() //user not found. ////mongodb query - you man not find user but treats as success, it searched and returned nothing - null - success {we might not get the user}
        }
        res.send(user) //status will be 200, you will user object.
                     
    }).catch((e)=>{
        res.status(500).send()
    })
 })
const _id = req.params.id
User.findById(_id)

when we are using mongodb native driver we used to write new ObjectID("objectID") ex: findOne({_id: new ObjectID("string objectid..")
 here we are not doing it, mongoose converts string ids (5cedfge..)to object ids

/users/:id ==== req.params.id
post /users json body {} === req.body ===> update in users model ==> const user = new User({req.body}) then user.save(){save to db}.then().catch

J17
Promise chaining
Till now every time we used promise we did only one asynchronous thing. ex: findById
what if we want to use one thing and then something else? ex: mark a task as complete and get the records of incompleted tasks
two asynchronous things. one needs to happen and then another.

lets see how we write without promise chaining

const add = (a, b)=> {  //parameters
    return new Promise((resolve, reject)=>{
            setTimeout(()=>{
                resolve(a + b)          //when add func called, we are returning a promises after waiting for 2 seconds
            }, 2000)
    })
}

add(1, 2).then((sum)=>{
    console.log(sum)
    //what if I want to do add one more async task ex: I want to add one more value to returned sum value.
    add(sum, 3).then((sum2)=>{      //second async call. one promise nested inside another
        console.log(sum2)
    }).catch((e)=>{
        console.log(e)
    })
}).catch((e)=>{
    console.log(e)
})
Issue with above code
1. when we want to perform another asyn task we are calling add func which returns promise and adding .then and .catch
    basically "Nesting"  what if we have around 20 asyn calls then will be nested too long {complex}
2. we are duplicating the code, writing .catch for all promises

solution: we can do promises chaining this is achieved by returning a promise from first asyc task
    and on that promise we can do .then {as it is promise we will have resolve and reject } and for all promises we can write one .catch.

add(1, 2).then((sum)=>{ //.then executes when add(1,2) fulfills
    console.log(sum)
    return add(sum, 3)  //returning a promise
}).then((sum2)=>{           //.then executes when add(sum,3) fulfills.
        console.log(sum2)   
    })
}).catch((e)=>{            //.catch executes for reject - this is for two promises
    console.log(e)

will see the same ex with findAndUpdate and getting the count

mongoose promises and chaining syntax
require mongoose file to connect to db and require User model
ex that we are working - find a user by id and update age = 1 and find all the users with that age
mongoosejs.com>queries> Model.findAndUpdate
we have updateOne and updateMany also  //do not return document
findOneAndUpdate and findByIdAndUpdate() //return document {promise}
grab the id of a user from robo 3t

User.findByIdAndUpdate('5c1ef..', {age: 1}).then((user)=>{        //return promise and here the document - updated or individual user that is going to update recheck.
    console.log(user)
    //check doc mongoosejs.com>api --Model.countDocuments() -- gives the doc count .//Model.count() - depreciated
    return User.countDocuments({age: 1})
}).then((count)=>{
    c.l(count)
}).catch((e)=>{
    c.l(e)
})

findByIdAndUpdate('',{}) takes two arguments  1. find by id -string simple string id no need of new ObjectID('5c20ee00')
mongoose does it for us 2. what are the updates - {age:1} updating age field value to 1. no need to use $set
 mongoose does it for us as it uses mongodb native driver behind the scenes
after updating the document returns promise

return promise from findByIdAndUpdate to do promise chaining.

deprecation warning: given by mongodb native driver
findByIdAndDelete - find doc with the specified id and deletes that doc.

async-await:
one more topic related to asynchronous programming.
async-await - makes it so easy to work with our asynchronous promise based code.
 writing code that looks more synchronous than asynchronous

asynn-await is merely small set of tools makes it easy to work with promises. still gonna using same old promise methods
 the only thing that gonna change is how we gonna manage our asynchronous code

will be using async-await in all our routes

const dowork = ()=>{
}
console.log(dowork()) //o/p undefined
we know that JS gonna return undefined when we do not return anything from a func which is called.

async key word , allows us to create async func in that func we are going to use await feature
mark a func as async func which is done by adding async keyword infront of the func declartion.
const dowork = async()=>{
}
console.log(dowork())
o/p: Promise {undefined}
when we call a async func it returns a promise and fulfilled with undefined as a value

async func always returns a promise. that promise is fulfilled with the value you as a developer choose to return from a func

const dowork = async()=>{
    return 'srk'            /asyn func always returns promise, here it is not just string as we are returning a string from our func 
                            //as it is asyn func then it returns promise which is fulfilled by value returned here string
}
console.log(dowork())
o/p: Promise {srk} 
when we call a async func which is returning a string, it returns a promise which is fulfilled with the string here 'srk' as a value

As dowork() is returning promise we can do .then and .catch instead of logging into console

const dowork = async()=>{
    throw new Error('Something went wrong')     //error-rejecting the promise with that error - .catch block
    return 'srk'            //returning a value, fulfilling the value of the promise.
}
dowork().then((result)=>{
    console.log(result)   //output - srk
}).catch((e)=>{
    console.log(e)
})
await operator feature:
how is it going to make our asynchronous tasks with ease 

Take our previous promise ex
const add = (a, b)=> {  
    return new Promise((resolve, reject)=>{
            setTimeout(()=>{
                resolve(a + b)   
            }, 2000)
    })
}
with promise chaining
add(1,2).then((sum)=>{
    console.log(sum)
    return add(sum,2)
}).then((sum2)=>{
    c.l(sum2)
}).catch((e)=>{
    c.l(e)
})

with asyn await:
const add = (a, b)=> {  
    return new Promise((resolve, reject)=>{
            setTimeout(()=>{
                resolve(a + b)   
            }, 2000)
    })
}
copy paste add func without changing single thing about it. this is done intentionally. when working with async await
you dont have to change how ur promise functions internally. all you do is change how you work with them
for us, mongoose does not need to write library in order us to use async await. mongoose supports Promises
so as a consumer of those promises we can use async await if we want to. 

const dowork = async ()=>{
    //await operator is used with a promise. await add(1,2) where do I get access to the data? if we are not using async-await
    //we use .then call and data can be accessed in that callback func {.then(()=>)}

     const sum =  await add(1,2) //add() looks like standard synchronous func. we can create a var to get access to the value that the promise is fulfilled.
                                //we have to wait 2secs. the adv is syntactical. we can return sum or call as many as add func calls - asynchronous
                                //fulfills promise and .then func will execute when we call dowork()
    //able to use code that looks like synchronous perform asynchronous task
     const sum1 = await add(sum, 2) //code is much simpler than promise changing. 
     const sum2 = await add(sum2, 2)
     return sum2                        //return promise after 6 seconds
    }

dowork().then((result)=>{       //promise fulfills so .then executes
    console.log(result)   
}).catch((e)=>{
    console.log(e)
})

advantage:
1. code is much simpler than promise chaining. not using many functions and return func values. leds some confusion situations
2. scope - when we use two .then - you cannot access first .then var in second so the scope is limited
we need to create one variable in parent scope and do all the stuff but in
asyn func everything come under one scope as defined in above ex: sum, sum1. sum2

Handling error
const add = (a, b)=> {  
    return new Promise((resolve, reject)=>{
            setTimeout(()=>{
                if(a < 0 || b<0) {
                    return reject('values must be positive ')
                }
                resolve(a + b)   
            }, 2000)
    })
}
const dowork = async()=>{
     const sum =  await add(1,2) return promise
     const sum1 = await add(sum, 2)
     const sum2 = await add(sum2, -1)   //after 6 secs fails and goes to .catch block.
     return sum2                    
    }

dowork().then((result)=>{       //promise fulfills so .then executes
    console.log(result)   
}).catch((e)=>{
    console.log(e)
})

The await operator is used with promises in asynchronous functions. The await operator allows you to work with promises in a way
that looks like synchronous code. If the promise is fulfilled, the fulfilled value can be
accessed as the return value from the function.

It’s important to note that async and await are syntax enhancements for working with
promises. Promises are still at the core of asynchronous code that uses async and await.


User.findByIdAndUpdate('5c1ef..', {age: 1}).then((user)=>{
    console.log(user)
    return User.countDocuments({age: 1})
}).then((count)=>{
    c.l(count)
}).catch((e)=>{
    c.l(e)
})

 will work on above function using async-await

const updateUserAgeAndGetCount = async (id, age) => {
    const user = await User.findByIdAndUpdate(id, {age})          //destructured age . findByIdAndUpdate returns promise
    const usersCount = await User.countDocuments({age}) //awaits for the promise
    return usersCount
}

updateUserAgeAndGetCount('5c1ef..', {age: 1}).then((usersCount)=>{c.l(usersCount)}).catch((e)=>{c.l(e)})

Integrating async-await in routes:
index.js file

app.post('/users', (req,res)=>{ 
    const user = new User({ req.body})
    user.save().then(()=>{  
        res.status(201).send(user)   
    }).catch((error)=>{
        res.status(400).send(error) 
    })                  

})
making above route to use async-await

//when you add async it changes the behavior of the func. func goes from returing whatever value you return to always returning a promise
//goodnews is that express doesnot use the return value from the func . express doesnot care what we return 
//instead we use request and response to tell express what we want to do. in this case we added the async functionality
//without changing the behavior at all

app.post('/users', async (req,res)=>{ //take this func which we pass to express and mark it async func

    const user = new User({ req.body})  //we send json via request body from postman.
    
     //   await user.save()       //await the promise that is coming from .save(). At this point we have saved the user, 
                                //everything that comes after this line is only going to run once the was saved. either success or unsuccessfully
        //next statement only runs if the promise above fulfills. if it is rejected rest of the function gets stop. eevrything next to it never ran.
//so we use try catch

        try {
            await user.save() //if this promise fullfills, goes to next step else goes to catch block
            res.status(201).send(user)
        } catch(e) {
            res.status(400).send(e)
        }
})
//eleminating .then calls
headover postman send good data {json body - required fields for user model} - 201 and bad data - 400

ex2:
app.get('/users', async (req,res)=>{
    try {
        const users = await User.find({})
        res.send(users)
    } catch (e) {
        res.status(500).send()
    }

})
ex3:
app.get('/users/:id', (req,res)=>{
    const _id = req.params.id
    try {
        const user = await User.find({_id})
        if(!user) {
            return res.status(404).send()
        }
        res.send(user)
    } catch (e) {
        res.status(500).send()
    }
})

Http endpoint for updating resources: express provides delete method
we use Patch http method and task is to update single user

app.patch('/users/:id', async (req,res)=>{

    const updates = Object.keys(req.body)
    const allowedUpdates = ["name","email","password","age"]

    const validOperation = updates.every((update)=>{
                return allowedUpdates.includes(update)
            })  

    if(!validOperation) {
        return res.status(400).send({"error":"Invalid updates!"})
    }
 
    try {
       const user = await User.findByIdAndUpdate(req.params.id, {req.body}, {new: true, runValidators: true})
        //findByIdAndUpdate mongoose method & $set is not req. mongoose handles it

       if(!user) {
          return res.status(404).send()
       }
       
       res.send(user)

    } catch (e) {
        res.status(400).send(e) //two things 1.network error - unable to connect to db - send 500
                                //2. validation issues ex: for name instead of string value user provided empty string. 
                                //so sending 500 is wrong for both cases. use 400
    }
})

1. we are accepting fields to update via req json body. so if user provide a field which does not exist in user model/document
express is sending 200 status nd ignores the field ex:height . to do defensive programming we are checking the fields which user want to update


    const updates = Object.keys(req.body)
    Object.keys(req.body) -- object.keys creates/returns a array of strings here keys provided by user in req json body

    const allowedUpdates = ["name","email","password","age"] //not providing _id

    const validOperation = updates.every((update)=>{
                return allowedUpdates.includes(update)
            }) 

    every is js array method. it returns true if all the array elements are true ex: if there are 10 elements , it returns true only
    if 10 elements/conditions are true else false

    we are checking the fields provided by user if that field doesnot exist we send 400 response
2. 
try {
       const user = await User.findByIdAndUpdate(req.params.id, {req.body}, {new: true, runValidators: true})

      1.  we are getting id from req params so req.params.id --sending via url in postman
      2. instead of hardcoding we are getting fields to update from user via req.body json
      3. third argument is options object - new:true is when findByIdAndUpdate operation performed
        by using new:true it sends the updated user with updated fields else it sends the user when it finds

        run validator - required fields, types

        next steps only run when the promise fulfills else goes to catch block
       if(!user) {
           res.status(404).send()
       }
       
       //if there is no user found by he query findByIdAndUpdate we send 404 

       res.send(user)

    } catch (e) {
        res.status(400).send()
    }

Delete:
app.get('/users/:id', (req,res)=>{

    try{
        const user = await User.findByIdAndDelete(req.params.id)
        if(!user) {
            return res.status(404).send()
        }
        res.send(user) //deleted user
    } catch (e) {
        res.status(500).send()
    }
})

separate route files:
refactor
currently index.js file has every single route tasks and users routes {break it in small files}. separate users and tasks routes

setting up multiple express routes will be combining together to create complete application

4steps process:

const router = new express.Router() //creating a new router
app.use(router) //registering with existing express app
router.get('/users', (req,res)=>{res.send('test')}) //setup the routes
module.exports = router //can be used in diff files.

create folder routers - user.js {user router}

const express = require('express')
const router = new express.Router()

router.get('/test',(req,res)=>{res.send('from other file')})
module.exports = router

index.js is the main file so import user router in index.js
const userRouter = require('/routers/user')

app.use(userRouter). register with our existing app
change all app.get to router.get()...

1big file>split to 3> index.js creates express app > what this express app does in defined in other files {router}

Authentication and security:
all of the api endpoints are publicly accessible. anyone can come along and do something - delete data etc
user need to sign up or login before they gonna do be able to do something. create a task or delete a task
by forcing user to login, we are creating a relationship b/w user and task. this makes sure user 1 cannot see user 32 task

Passwords


















